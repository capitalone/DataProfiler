{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alive-chain",
   "metadata": {},
   "source": [
    "# Complex Data Type Detection using Data Labeler component of Data Profiler"
   ]
  },
  {
   "cell_type": "raw",
   "id": "passing-bundle",
   "metadata": {},
   "source": [
    "In this example, we utilize the data labeler component of the Data Profiler to detect the sensitive information for both structured and unstructured data. Data Profiler can be transfer learned with the new datasets to get better results on some specific domains.\n",
    "\n",
    "First, let's import the libraries needed for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "external-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "import os\n",
    "import dataprofiler as dp\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-mission",
   "metadata": {},
   "source": [
    "## Structured data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dress-curve",
   "metadata": {},
   "source": [
    "Look at the data using data reader class of the data profiler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affected-kruger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>host</th>\n",
       "      <th>src</th>\n",
       "      <th>proto</th>\n",
       "      <th>type</th>\n",
       "      <th>srcport</th>\n",
       "      <th>destport</th>\n",
       "      <th>srcip</th>\n",
       "      <th>locale</th>\n",
       "      <th>localeabbr</th>\n",
       "      <th>postalcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>owner</th>\n",
       "      <th>comment</th>\n",
       "      <th>int_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/3/13 21:53</td>\n",
       "      <td>groucho-oregon</td>\n",
       "      <td>1032051418</td>\n",
       "      <td>TCP</td>\n",
       "      <td></td>\n",
       "      <td>6000</td>\n",
       "      <td>1433</td>\n",
       "      <td>61.131.218.218</td>\n",
       "      <td>Jiangxi Sheng</td>\n",
       "      <td>36</td>\n",
       "      <td></td>\n",
       "      <td>28.55</td>\n",
       "      <td>115.9333</td>\n",
       "      <td></td>\n",
       "      <td>He my polite be object oh change. Consider no ...</td>\n",
       "      <td>9464.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/3/13 21:57</td>\n",
       "      <td>groucho-oregon</td>\n",
       "      <td>1347834426</td>\n",
       "      <td>UDP</td>\n",
       "      <td></td>\n",
       "      <td>5270</td>\n",
       "      <td>5060</td>\n",
       "      <td>80.86.82.58</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3731.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/3/13 21:58</td>\n",
       "      <td>groucho-oregon</td>\n",
       "      <td>2947856490</td>\n",
       "      <td>TCP</td>\n",
       "      <td></td>\n",
       "      <td>2489</td>\n",
       "      <td>1080</td>\n",
       "      <td>175.180.184.106</td>\n",
       "      <td>Taipei</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>25.0392</td>\n",
       "      <td>121.525</td>\n",
       "      <td></td>\n",
       "      <td>Of on affixed civilly moments promise explain ...</td>\n",
       "      <td>3963.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/3/13 21:58</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UDP</td>\n",
       "      <td></td>\n",
       "      <td>43235</td>\n",
       "      <td>1900</td>\n",
       "      <td></td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "      <td>97124</td>\n",
       "      <td>45.5848</td>\n",
       "      <td>-122.9117</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1422.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/3/13 21:58</td>\n",
       "      <td>groucho-singapore</td>\n",
       "      <td>3587648279</td>\n",
       "      <td>TCP</td>\n",
       "      <td></td>\n",
       "      <td>56577</td>\n",
       "      <td>80</td>\n",
       "      <td>213.215.43.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>48.86</td>\n",
       "      <td>2.35</td>\n",
       "      <td></td>\n",
       "      <td>Affronting everything discretion men now own d...</td>\n",
       "      <td>9271.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime               host         src proto type srcport destport  \\\n",
       "0  3/3/13 21:53     groucho-oregon  1032051418   TCP         6000     1433   \n",
       "1  3/3/13 21:57     groucho-oregon  1347834426   UDP         5270     5060   \n",
       "2  3/3/13 21:58     groucho-oregon  2947856490   TCP         2489     1080   \n",
       "3  3/3/13 21:58                                  UDP        43235     1900   \n",
       "4  3/3/13 21:58  groucho-singapore  3587648279   TCP        56577       80   \n",
       "\n",
       "             srcip         locale localeabbr postalcode latitude  longitude  \\\n",
       "0   61.131.218.218  Jiangxi Sheng         36               28.55   115.9333   \n",
       "1      80.86.82.58                                            51          9   \n",
       "2  175.180.184.106         Taipei                        25.0392    121.525   \n",
       "3                          Oregon         OR      97124  45.5848  -122.9117   \n",
       "4    213.215.43.23                                         48.86       2.35   \n",
       "\n",
       "  owner                                            comment  int_col  \n",
       "0        He my polite be object oh change. Consider no ...  9464.00  \n",
       "1                                                           3731.00  \n",
       "2        Of on affixed civilly moments promise explain ...  3963.00  \n",
       "3                                                           1422.00  \n",
       "4        Affronting everything discretion men now own d...  9271.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dp.Data(\"../data/structured/aws_honeypot_marx_geo.csv\")\n",
    "df_data = data.data\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "described-somerset",
   "metadata": {},
   "source": [
    "The data contains 16 columns, each of which has different data label. Next, we will use data labeler of the data profiler to predict the label for each column in this tabular dataset. To use only the labeling functionality, other options are disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separate-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.int.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.float.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.text.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:1045: UserWarning: data_profiler.labelers.character_level_cnn_model is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      " 62%|██████▎   | 10/16 [00:02<00:00,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f59b0303510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f59b0303510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [00:02<00:00, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f59b0303510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# set option to run only data labeler\n",
    "profile_options = dp.ProfilerOptions()\n",
    "profile_options.set({\"text.is_enabled\": False, \n",
    "                     \"int.is_enabled\": False, \n",
    "                     \"float.is_enabled\": False, \n",
    "                     \"order.is_enabled\": False, \n",
    "                     \"category.is_enabled\": False, \n",
    "                     \"datetime.is_enabled\": False,})\n",
    "\n",
    "profile = dp.Profiler(data, profiler_options=profile_options)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "julian-telephone",
   "metadata": {},
   "source": [
    "The results are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "injured-commission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column             Prediction\n",
      "0     datetime  DATETIME|PHONE_NUMBER\n",
      "1         host                UNKNOWN\n",
      "2          src       BAN|PHONE_NUMBER\n",
      "3        proto                UNKNOWN\n",
      "4         type                INTEGER\n",
      "5      srcport                ADDRESS\n",
      "6     destport                INTEGER\n",
      "7        srcip                   IPV4\n",
      "8       locale                UNKNOWN\n",
      "9   localeabbr                INTEGER\n",
      "10  postalcode                INTEGER\n",
      "11    latitude                  FLOAT\n",
      "12   longitude                  FLOAT\n",
      "13       owner                   None\n",
      "14     comment                UNKNOWN\n",
      "15     int_col                  FLOAT\n"
     ]
    }
   ],
   "source": [
    "# get the prediction from data profiler\n",
    "def get_structured_results(results):\n",
    "    columns = []\n",
    "    predictions = []\n",
    "    for col in results['data_stats']:\n",
    "        columns.append(col)\n",
    "        predictions.append(results['data_stats'][col]['data_label'])\n",
    "\n",
    "    df_results = pd.DataFrame({'Column': columns, 'Prediction': predictions})\n",
    "    return df_results\n",
    "\n",
    "results = profile.report()    \n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "rubber-relevance",
   "metadata": {},
   "source": [
    "The results show that the data profiler is able to detect sensitive information such as datetime, ipv4, or address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-distribution",
   "metadata": {},
   "source": [
    "### Train data labeler from scratch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "wrapped-charge",
   "metadata": {},
   "source": [
    "Data labeler can be trained from scratch with the new list of labels. Below, we show an example of training the data labeler on a dataset with labels given as the columns of that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virtual-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:1045: UserWarning: data_profiler.labelers.character_level_cnn_model is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 (3s), loss: 4.576456 - acc: 0.102176 - f1_score 0.102176 -- val_f1: 0.043341 - val_precision: 0.030926 - val_recall 0.128533\n",
      "EPOCH 1 (0s), loss: 3.118322 - acc: 0.159318 - f1_score 0.159318 -- val_f1: 0.057850 - val_precision: 0.053500 - val_recall 0.146838\n",
      "EPOCH 2 (0s), loss: 2.257035 - acc: 0.277035 - f1_score 0.277035 -- val_f1: 0.114242 - val_precision: 0.116730 - val_recall 0.202152\n",
      "EPOCH 3 (0s), loss: 1.674754 - acc: 0.491612 - f1_score 0.491612 -- val_f1: 0.217278 - val_precision: 0.229349 - val_recall 0.286557\n",
      "EPOCH 4 (0s), loss: 1.319068 - acc: 0.626576 - f1_score 0.626576 -- val_f1: 0.256808 - val_precision: 0.354095 - val_recall 0.322086\n",
      "EPOCH 5 (0s), loss: 1.068586 - acc: 0.712753 - f1_score 0.712753 -- val_f1: 0.264931 - val_precision: 0.500542 - val_recall 0.320535\n",
      "EPOCH 6 (0s), loss: 0.901625 - acc: 0.755659 - f1_score 0.755659 -- val_f1: 0.294112 - val_precision: 0.536594 - val_recall 0.338628\n",
      "EPOCH 7 (0s), loss: 0.770896 - acc: 0.788141 - f1_score 0.788141 -- val_f1: 0.341869 - val_precision: 0.560409 - val_recall 0.385460\n",
      "EPOCH 8 (0s), loss: 0.674719 - acc: 0.817706 - f1_score 0.817706 -- val_f1: 0.401297 - val_precision: 0.657059 - val_recall 0.451583\n",
      "EPOCH 9 (0s), loss: 0.593525 - acc: 0.838224 - f1_score 0.838224 -- val_f1: 0.489408 - val_precision: 0.706643 - val_recall 0.533402\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: data_labeler_saved/assets\n"
     ]
    }
   ],
   "source": [
    "# the column 'comment' has been changed to UNKNOWN, as data labeler requires at least one column with label BACKGROUND\n",
    "data = dp.Data(\"../data/structured/aws_honeypot_marx_geo_retrain.csv\")\n",
    "\n",
    "# split data to training and test set\n",
    "split_ratio = 0.2\n",
    "df = data.data.sample(frac=1).reset_index(drop=True)\n",
    "data_train = df[:int((1 - split_ratio) * len(df))]\n",
    "data_test = df[int((1 - split_ratio) * len(df)):]\n",
    "\n",
    "# train new data labeler with column names as labels\n",
    "if not os.path.exists('data_labeler_saved'):\n",
    "    os.makedirs('data_labeler_saved')\n",
    "\n",
    "data_labeler = dp.train_structured_labeler(\n",
    "    data=data_train,\n",
    "    save_dirpath=\"data_labeler_saved\",\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "taken-chess",
   "metadata": {},
   "source": [
    "The trained data labeler is then used by Data Profiler to provide the prediction on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fantastic-geology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.int.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.float.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.text.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "100%|██████████| 16/16 [00:00<00:00, 29.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column Prediction\n",
      "0     datetime        src\n",
      "1         host       host\n",
      "2          src        src\n",
      "3        proto      proto\n",
      "4         type      proto\n",
      "5      srcport        src\n",
      "6     destport        src\n",
      "7        srcip      srcip\n",
      "8       locale        src\n",
      "9   localeabbr      proto\n",
      "10  postalcode        src\n",
      "11    latitude        src\n",
      "12   longitude   latitude\n",
      "13       owner       None\n",
      "14     UNKNOWN    UNKNOWN\n",
      "15     int_col    int_col\n"
     ]
    }
   ],
   "source": [
    "# predict with data labeler object\n",
    "profile_options.set({'data_labeler.data_labeler_object': data_labeler})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "current-grade",
   "metadata": {},
   "source": [
    "Another way to use the trained data labeler is through the directory path of the saved labeler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "digital-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.int.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.float.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "../../dataprofiler/profilers/profiler_options.py:291: UserWarning: ProfilerOptions.structured_options.text.numeric_stats: The numeric stats are completely disabled.\n",
      "  .format(variable_path))\n",
      "../../dataprofiler/profilers/profiler_options.py:554: UserWarning: The data labeler passed in will be used, not through the directory of the default model\n",
      "  warnings.warn(\"The data labeler passed in will be used,\"\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "100%|██████████| 16/16 [00:00<00:00, 31.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column Prediction\n",
      "0     datetime        src\n",
      "1         host       host\n",
      "2          src        src\n",
      "3        proto      proto\n",
      "4         type      proto\n",
      "5      srcport        src\n",
      "6     destport        src\n",
      "7        srcip      srcip\n",
      "8       locale        src\n",
      "9   localeabbr      proto\n",
      "10  postalcode        src\n",
      "11    latitude        src\n",
      "12   longitude   latitude\n",
      "13       owner       None\n",
      "14     UNKNOWN    UNKNOWN\n",
      "15     int_col    int_col\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict with data labeler loaded from path\n",
    "profile_options.set({'data_labeler.data_labeler_dirpath': 'data_labeler_saved'})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-spelling",
   "metadata": {},
   "source": [
    "## Unstructured data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "single-aging",
   "metadata": {},
   "source": [
    "Beside structured data, data profiler detects the sensitive information on the unstructured text. We use a sample of spam email in Enron email dataset for this demo. As above, we start investigating the content of the given email sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "trained-admission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Message-ID: <14332367.1075858794078.JavaMail.evans@thyme>\n",
      "Date: Mon, 15 Oct 2001 10:51:17 -0700 (PDT)\n",
      "From: w..white@enron.com\n",
      "To: john.postlethwaite@enron.com\n",
      "Subject: RE: PGE\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: White, Stacey W. </O=ENRON/OU=NA/CN=RECIPIENTS/CN=SWHITE>\n",
      "X-To: Postlethwaite, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JPOSTLE>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\SWHITE (Non-Privileged)\\Sent Items\n",
      "X-Origin: White-S\n",
      "X-FileName: SWHITE (Non-Privileged).pst\n",
      "\n",
      "All I ever saw was the e-mail from the Office of the Chair.\n",
      "\n",
      "Stacey\n",
      "\n",
      " -----Original Message-----\n",
      "From:   Postlethwaite, John  \n",
      "Sent:   Monday, October 15, 2001 12:47 PM\n",
      "To:     White, Stacey W.\n",
      "Subject:        PGE\n",
      "\n",
      "Have you heard any more regarding the PGE sale? It's funny, here nobody is talking about it. I guess that means that it's no big deal here, but you think they would have send something.\n",
      "\n",
      "By the way, when I saw Casey, that girl is getting skinnier by the day. I have never personally seen her that thin before.\n",
      "\n",
      "\n",
      "\n",
      "John Postlethwaite\n",
      "EPMI-West Power Risk Management\n",
      "503-464-7756\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = dp.Data(\"../data/unstructured/email-enron-sample\")\n",
    "print(data.data[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "premier-globe",
   "metadata": {},
   "source": [
    "By default, data profiler predicts the results at the character level for unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "descending-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:1045: UserWarning: data_profiler.labelers.character_level_cnn_model is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x7f58ec6d8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[array([ 1.,  1.,  1., ..., 16.,  1.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "data_labeler = dp.DataLabeler(labeler_type='unstructured')\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = data_labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print(predictions['pred'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "available-superintendent",
   "metadata": {},
   "source": [
    "In addition to the character-level result, data profiler provides the results at the word level following the standard NER (Named Entity Recognition), e.g., utilized by spaCy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statewide-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=======================Prediction======================\n",
      "\n",
      "<14332367: QUANTITY\n",
      "--------------------------------------------------------\n",
      "evans@thyme>: EMAIL_ADDRESS\n",
      "--------------------------------------------------------\n",
      "Mon, 15: DATE\n",
      "--------------------------------------------------------\n",
      "Oct 2001 10: DATETIME\n",
      "--------------------------------------------------------\n",
      "-0700: TIME\n",
      "--------------------------------------------------------\n",
      "white@enron.com: EMAIL_ADDRESS\n",
      "--------------------------------------------------------\n",
      "john.postlethwaite@enron.com: EMAIL_ADDRESS\n",
      "--------------------------------------------------------\n",
      "7bit: QUANTITY\n",
      "--------------------------------------------------------\n",
      "White, Stacey W: PERSON\n",
      "--------------------------------------------------------\n",
      "</O=ENRON/OU=NA/CN=RECIPIENTS/CN=SWHITE>: HASH_OR_KEY\n",
      "--------------------------------------------------------\n",
      "Postlethwaite, John: PERSON\n",
      "--------------------------------------------------------\n",
      "</O=ENRON/OU=NA/CN=RECIPIENTS/CN=JPOSTLE>: HASH_OR_KEY\n",
      "--------------------------------------------------------\n",
      "-----Original: QUANTITY\n",
      "--------------------------------------------------------\n",
      "Postlethwaite, John: PERSON\n",
      "--------------------------------------------------------\n",
      "Monday, October 15, 2001 12:47: DATETIME\n",
      "--------------------------------------------------------\n",
      "PM: US_STATE\n",
      "--------------------------------------------------------\n",
      "White, Stacey W: PERSON\n",
      "--------------------------------------------------------\n",
      "John: PERSON\n",
      "--------------------------------------------------------\n",
      "Risk Management: PERSON\n",
      "--------------------------------------------------------\n",
      "503-464-7756: PHONE_NUMBER\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# convert prediction to word format and ner format\n",
    "# Set the output to the NER format (start position, end position, label)\n",
    "data_labeler.set_params(\n",
    "    { 'postprocessor': { 'output_format':'ner', 'use_word_level_argmax':True } } \n",
    ")\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = data_labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print('\\n')\n",
    "print('=======================Prediction======================\\n')\n",
    "for pred in predictions['pred'][0]:\n",
    "    print('{}: {}'.format(data.data[0][pred[0]: pred[1]], pred[2]))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "overall-acrylic",
   "metadata": {},
   "source": [
    "Data profiler identifies sensitive information such as datetime, email address, person names, and phone number. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
