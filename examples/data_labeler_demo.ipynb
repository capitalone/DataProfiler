{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spoken-reunion",
   "metadata": {},
   "source": [
    "# Sensitive Data Detection with the Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-bidder",
   "metadata": {},
   "source": [
    "In this example, we utilize the Labeler component of the Data Profiler to detect the sensitive information for both structured and unstructured data. In addition, we show how to train the Labeler on some specific dataset with different list of entities.\n",
    "\n",
    "First, let's dive into what the Labeler is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965b83b",
   "metadata": {},
   "source": [
    "## What is the Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c643f",
   "metadata": {},
   "source": [
    "The Labeler is a pipeline designed to make building, training, and predictions with ML models quick and easy. There are 3 major components to the Labeler: the preprocessor, the model, and the postprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0aeb4",
   "metadata": {},
   "source": [
    "![alt text](DL-Flowchart.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550323c7",
   "metadata": {},
   "source": [
    "Each component can be switched out individually to suit your needs. As you might expect, the preprocessor takes in raw data and prepares it for the model, the model performs the prediction or training, and the postprocessor takes prediction results and turns them into human-readable results. \n",
    "\n",
    "Now let's run some examples. Start by importing all the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "scientific-stevens",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '..')\n",
    "import dataprofiler as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125b215",
   "metadata": {},
   "source": [
    "## Structured Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-devon",
   "metadata": {},
   "source": [
    "We'll use the aws honeypot dataset in the test folder for this example. First, look at the data using the Data Reader class of the Data Profiler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adjusted-native",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEID6</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ACCREDAGENCY</th>\n",
       "      <th>INSTURL</th>\n",
       "      <th>NPCURL</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>DEATH_YR2_RT</th>\n",
       "      <th>SEARCH_STRING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>35762</td>\n",
       "      <td>Southern Association of Colleges and Schools C...</td>\n",
       "      <td>www.aamu.edu/</td>\n",
       "      <td>www.aamu.edu/admissions-aid/tuition-fees/net-p...</td>\n",
       "      <td>34.783368</td>\n",
       "      <td>-86.568502</td>\n",
       "      <td>NULL</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>Alabama A &amp; M University AAMU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1052</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>Southern Association of Colleges and Schools C...</td>\n",
       "      <td>https://www.uab.edu</td>\n",
       "      <td>https://uab.studentaidcalculator.com/survey.aspx</td>\n",
       "      <td>33.505697</td>\n",
       "      <td>-86.799345</td>\n",
       "      <td>NULL</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25034</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>36117-3553</td>\n",
       "      <td>Southern Association of Colleges and Schools C...</td>\n",
       "      <td>www.amridgeuniversity.edu</td>\n",
       "      <td>www2.amridgeuniversity.edu:9091/</td>\n",
       "      <td>32.362609</td>\n",
       "      <td>-86.17401</td>\n",
       "      <td>74</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>Amridge University Southern Christian Universi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1055</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>35899</td>\n",
       "      <td>Southern Association of Colleges and Schools C...</td>\n",
       "      <td>www.uah.edu</td>\n",
       "      <td>finaid.uah.edu/</td>\n",
       "      <td>34.724557</td>\n",
       "      <td>-86.640449</td>\n",
       "      <td>NULL</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>University of Alabama in Huntsville UAH  Unive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>36104-0271</td>\n",
       "      <td>Southern Association of Colleges and Schools C...</td>\n",
       "      <td>www.alasu.edu</td>\n",
       "      <td>www.alasu.edu/cost-aid/tuition-costs/net-price...</td>\n",
       "      <td>32.364317</td>\n",
       "      <td>-86.295677</td>\n",
       "      <td>NULL</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>Alabama State University</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OPEID6                               INSTNM         ZIP  \\\n",
       "0   1002             Alabama A & M University       35762   \n",
       "1   1052  University of Alabama at Birmingham  35294-0110   \n",
       "2  25034                   Amridge University  36117-3553   \n",
       "3   1055  University of Alabama in Huntsville       35899   \n",
       "4   1005             Alabama State University  36104-0271   \n",
       "\n",
       "                                        ACCREDAGENCY  \\\n",
       "0  Southern Association of Colleges and Schools C...   \n",
       "1  Southern Association of Colleges and Schools C...   \n",
       "2  Southern Association of Colleges and Schools C...   \n",
       "3  Southern Association of Colleges and Schools C...   \n",
       "4  Southern Association of Colleges and Schools C...   \n",
       "\n",
       "                     INSTURL  \\\n",
       "0              www.aamu.edu/   \n",
       "1        https://www.uab.edu   \n",
       "2  www.amridgeuniversity.edu   \n",
       "3                www.uah.edu   \n",
       "4              www.alasu.edu   \n",
       "\n",
       "                                              NPCURL   LATITUDE   LONGITUDE  \\\n",
       "0  www.aamu.edu/admissions-aid/tuition-fees/net-p...  34.783368  -86.568502   \n",
       "1   https://uab.studentaidcalculator.com/survey.aspx  33.505697  -86.799345   \n",
       "2                   www2.amridgeuniversity.edu:9091/  32.362609   -86.17401   \n",
       "3                                    finaid.uah.edu/  34.724557  -86.640449   \n",
       "4  www.alasu.edu/cost-aid/tuition-costs/net-price...  32.364317  -86.295677   \n",
       "\n",
       "  RELAFFIL       DEATH_YR2_RT  \\\n",
       "0     NULL  PrivacySuppressed   \n",
       "1     NULL  PrivacySuppressed   \n",
       "2       74  PrivacySuppressed   \n",
       "3     NULL  PrivacySuppressed   \n",
       "4     NULL  PrivacySuppressed   \n",
       "\n",
       "                                       SEARCH_STRING  \n",
       "0                      Alabama A & M University AAMU  \n",
       "1               University of Alabama at Birmingham   \n",
       "2  Amridge University Southern Christian Universi...  \n",
       "3  University of Alabama in Huntsville UAH  Unive...  \n",
       "4                          Alabama State University   "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dp.Data(\"../dataprofiler/tests/data/csv/SchoolDataSmall.csv\")\n",
    "df_data = data.data\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ccf8a",
   "metadata": {},
   "source": [
    "We can directly predict the labels of a structured dataset on the cell level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19529af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['PAD', 'UNKNOWN', 'ADDRESS', 'BAN', 'CREDIT_CARD', 'DATE', 'TIME', 'DATETIME', 'DRIVERS_LICENSE', 'EMAIL_ADDRESS', 'UUID', 'HASH_OR_KEY', 'IPV4', 'IPV6', 'MAC_ADDRESS', 'PERSON', 'PHONE_NUMBER', 'SSN', 'URL', 'US_STATE', 'INTEGER', 'FLOAT', 'QUANTITY', 'ORDINAL']\n",
      "\n",
      "\n",
      "Label Mapping: {'PAD': 0, 'UNKNOWN': 1, 'ADDRESS': 2, 'BAN': 3, 'CREDIT_CARD': 4, 'DATE': 5, 'TIME': 6, 'DATETIME': 7, 'DRIVERS_LICENSE': 8, 'EMAIL_ADDRESS': 9, 'UUID': 10, 'HASH_OR_KEY': 11, 'IPV4': 12, 'IPV6': 13, 'MAC_ADDRESS': 14, 'PERSON': 15, 'PHONE_NUMBER': 16, 'SSN': 17, 'URL': 18, 'US_STATE': 19, 'INTEGER': 20, 'FLOAT': 21, 'QUANTITY': 22, 'ORDINAL': 23}\n",
      "\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e25e550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x16355cdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1626779d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x16355cdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function recreate_function.<locals>.restored_function_body at 0x1626779d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Predictions: ['INTEGER' 'UNKNOWN' 'INTEGER' ... 'UNKNOWN' 'UNKNOWN' 'UNKNOWN']\n",
      "\n",
      "\n",
      "Confidences: [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.54166667 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.         0.         ... 0.         0.         0.        ]\n",
      " [0.         1.         0.         ... 0.         0.         0.        ]\n",
      " [0.         1.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "labeler = dp.DataLabeler(labeler_type='structured')\n",
    "\n",
    "# print out the labels and label mapping\n",
    "print(\"Labels: {}\".format(labeler.labels)) \n",
    "print(\"\\n\")\n",
    "print(\"Label Mapping: {}\".format(labeler.label_mapping))\n",
    "print(\"\\n\")\n",
    "\n",
    "# make predictions and get labels for each cell going row by row\n",
    "# predict options are model dependent and the default model can show prediction confidences\n",
    "predictions = labeler.predict(data, predict_options={\"show_confidences\": True})\n",
    "\n",
    "# display prediction results\n",
    "print(\"Predictions: {}\".format(predictions['pred']))\n",
    "print(\"\\n\")\n",
    "\n",
    "# display confidence results\n",
    "print(\"Confidences: {}\".format(predictions['conf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af72e2c",
   "metadata": {},
   "source": [
    "The profiler uses the Labeler to perform column by column predictions. The data contains 16 columns, each of which has different data label. Next, we will use the Labeler of the Data Profiler to predict the label for each column in this tabular dataset. To use only the labeling functionality, other options of the Data Profiler are disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "secret-million",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.int.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.float.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.text.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the Null values in the columns... (with 11 processes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  9.63it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the statistics...  (with 4 processes)\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 1/11 [00:00<00:01,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 13 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [00:00<00:01,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [00:00<00:01,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 13 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [00:00<00:01,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [00:00<00:01,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [00:01<00:01,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [00:01<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [00:01<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165cd7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x15dae7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x15e51db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column       Prediction\n",
      "0          OPEID6          INTEGER\n",
      "1          INSTNM          UNKNOWN\n",
      "2             ZIP  INTEGER|ADDRESS\n",
      "3    ACCREDAGENCY          UNKNOWN\n",
      "4         INSTURL              URL\n",
      "5          NPCURL              URL\n",
      "6        LATITUDE            FLOAT\n",
      "7       LONGITUDE            FLOAT\n",
      "8        RELAFFIL          INTEGER\n",
      "9    DEATH_YR2_RT          UNKNOWN\n",
      "10  SEARCH_STRING          UNKNOWN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set options to only run the labeler\n",
    "profile_options = dp.ProfilerOptions()\n",
    "profile_options.set({\"text.is_enabled\": False, \n",
    "                     \"int.is_enabled\": False, \n",
    "                     \"float.is_enabled\": False, \n",
    "                     \"order.is_enabled\": False, \n",
    "                     \"category.is_enabled\": False, \n",
    "                     \"datetime.is_enabled\": False,})\n",
    "\n",
    "profile = dp.Profiler(data, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "def get_structured_results(results):\n",
    "    columns = []\n",
    "    predictions = []\n",
    "    for col in results['data_stats']:\n",
    "        columns.append(col)\n",
    "        predictions.append(results['data_stats'][col]['data_label'])\n",
    "\n",
    "    df_results = pd.DataFrame({'Column': columns, 'Prediction': predictions})\n",
    "    return df_results\n",
    "\n",
    "results = profile.report()    \n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-louisville",
   "metadata": {},
   "source": [
    "In this example, the results show that the Data Profiler is able to detect integers, URLs, and floats appropriately. Unknown is typically strings of text, which is appropriate for those columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-diploma",
   "metadata": {},
   "source": [
    "## Unstructured Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-coaching",
   "metadata": {},
   "source": [
    "Besides structured data, the Data Profiler detects the sensitive information on the unstructured text. We use a sample of spam email in Enron email dataset for this demo. As above, we start investigating the content of the given email sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-lounge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = \"Message-ID: <11111111.1111111111111.JavaMail.evans@thyme>\\n\" + \\\n",
    "        \"Date: Fri, 10 Aug 2005 11:31:37 -0700 (PDT)\\n\" + \\\n",
    "        \"From: w..smith@company.com\\n\" + \\\n",
    "        \"To: john.smith@company.com\\n\" + \\\n",
    "        \"Subject: RE: ABC\\n\" + \\\n",
    "        \"Mime-Version: 1.0\\n\" + \\\n",
    "        \"Content-Type: text/plain; charset=us-ascii\\n\" + \\\n",
    "        \"Content-Transfer-Encoding: 7bit\\n\" + \\\n",
    "        \"X-From: Smith, Mary W. </O=ENRON/OU=NA/CN=RECIPIENTS/CN=SSMITH>\\n\" + \\\n",
    "        \"X-To: Smith, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JSMITH>\\n\" + \\\n",
    "        \"X-cc: \\n\" + \\\n",
    "        \"X-bcc: \\n\" + \\\n",
    "        \"X-Folder: \\SSMITH (Non-Privileged)\\Sent Items\\n\" + \\\n",
    "        \"X-Origin: Smith-S\\n\" + \\\n",
    "        \"X-FileName: SSMITH (Non-Privileged).pst\\n\\n\" + \\\n",
    "        \"All I ever saw was the e-mail from the office.\\n\\n\" + \\\n",
    "        \"Mary\\n\\n\" + \\\n",
    "        \"-----Original Message-----\\n\" + \\\n",
    "        \"From:   Smith, John  \\n\" + \\\n",
    "        \"Sent:   Friday, August 10, 2005 13:07 PM\\n\" + \\\n",
    "        \"To:     Smith, Mary W.\\n\" + \\\n",
    "        \"Subject:        ABC\\n\\n\" + \\\n",
    "        \"Have you heard any more regarding the ABC sale? I guess that means that \" + \\\n",
    "        \"it's no big deal here, but you think they would have send something.\\n\\n\\n\" + \\\n",
    "        \"John Smith\\n\" + \\\n",
    "        \"123-456-7890\\n\"\n",
    "\n",
    "# convert string data to list to feed into the labeler\n",
    "data = [data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-segment",
   "metadata": {},
   "source": [
    "By default, the Data Profiler predicts the results at the character level for unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-acrobat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeler = dp.DataLabeler(labeler_type='unstructured')\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print(predictions['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-diabetes",
   "metadata": {},
   "source": [
    "In addition to the character-level result, the Data Profiler provides the results at the word level following the standard NER (Named Entity Recognition), e.g., utilized by spaCy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-universe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert prediction to word format and ner format\n",
    "# Set the output to the NER format (start position, end position, label)\n",
    "labeler.set_params(\n",
    "    { 'postprocessor': { 'output_format':'ner', 'use_word_level_argmax':True } } \n",
    ")\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print('\\n')\n",
    "print('=======================Prediction======================\\n')\n",
    "for pred in predictions['pred'][0]:\n",
    "    print('{}: {}'.format(data[0][pred[0]: pred[1]], pred[2]))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-tourism",
   "metadata": {},
   "source": [
    "Here, the Data Profiler is able to identify sensitive information such as datetime, email address, person names, and phone number in an email sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-disney",
   "metadata": {},
   "source": [
    "## Train the Labeler from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-twist",
   "metadata": {},
   "source": [
    "The Labeler can be trained from scratch with a new list of labels. Below, we show an example of training the Labeler on a dataset with labels given as the columns of that dataset. For brevity's sake, let's only train a few epochs with a subset of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-evaluation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dp.Data(\"../dataprofiler/tests/data/csv/SchoolDataSmall.csv\")\n",
    "df = data.data[[\"OPEID6\", \"INSTURL\", \"SEARCH_STRING\"]]\n",
    "df.head()\n",
    "\n",
    "# split data to training and test set\n",
    "split_ratio = 0.2\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "data_train = df[:int((1 - split_ratio) * len(df))]\n",
    "data_test = df[int((1 - split_ratio) * len(df)):]\n",
    "\n",
    "# train a new labeler with column names as labels\n",
    "if not os.path.exists('data_labeler_saved'):\n",
    "    os.makedirs('data_labeler_saved')\n",
    "\n",
    "labeler = dp.train_structured_labeler(\n",
    "    data=data_train,\n",
    "    save_dirpath=\"data_labeler_saved\",\n",
    "    epochs=10,\n",
    "    default_label=\"OPEID6\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-torture",
   "metadata": {},
   "source": [
    "The trained Labeler is then used by the Data Profiler to provide the prediction on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-panel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predict with the labeler object\n",
    "profile_options.set({'data_labeler.data_labeler_object': labeler})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-stand",
   "metadata": {},
   "source": [
    "Another way to use the trained Labeler is through the directory path of the saved labeler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-characterization",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict with the labeler loaded from path\n",
    "profile_options.set({'data_labeler.data_labeler_dirpath': 'data_labeler_saved'})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acedba0",
   "metadata": {},
   "source": [
    "## Transfer Learning a Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15fb1f",
   "metadata": {},
   "source": [
    "Instead of training a model from scratch, we can also transfer learn to improve the model and/or extend the labels. Again for brevity's sake, let's only train a few epochs with a small dataset at the cost of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104c374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dp.Data(\"../dataprofiler/tests/data/csv/SchoolDataSmall.csv\")\n",
    "df_data = data.data[[\"OPEID6\", \"INSTURL\", \"SEARCH_STRING\"]]\n",
    "\n",
    "\n",
    "# prep data\n",
    "df_data = df_data.reset_index(drop=True).melt()\n",
    "df_data.columns = [1, 0]  # labels=1, values=0 in that order\n",
    "df_data = df_data.astype(str)\n",
    "new_labels = df_data[1].unique().tolist()\n",
    "\n",
    "# load structured Labeler w/ trainable set to True\n",
    "labeler = dp.DataLabeler(labeler_type='structured', trainable=True)\n",
    "\n",
    "# Reconstruct the model to add each new label\n",
    "for label in new_labels:\n",
    "    labeler.add_label(label)\n",
    "\n",
    "# this will use transfer learning to retrain the labeler on your new\n",
    "# dataset and labels.\n",
    "# Setting labels with a list of labels or label mapping will overwrite the existing labels with new ones\n",
    "# Setting the reset_weights parameter to false allows transfer learning to occur\n",
    "model_results = labeler.fit(x=df_data[0], y=df_data[1], validation_split=0.2, \n",
    "                                 epochs=10, labels=None, reset_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78745f",
   "metadata": {},
   "source": [
    "Let's display the training results of the last epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b764aa8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"{:16s}  Precision  Recall  F1-score  Support\".format(\"\"))\n",
    "for item in model_results[-1][2]:\n",
    "    print(\"{:16s}  {:4.3f}      {:4.3f}   {:4.3f}     {:7.0f}\".format(item,\n",
    "                                                                      model_results[-1][2][item][\"precision\"],\n",
    "                                                                      model_results[-1][2][item][\"recall\"],\n",
    "                                                                      model_results[-1][2][item][\"f1-score\"],\n",
    "                                                                      model_results[-1][2][item][\"support\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44009522",
   "metadata": {},
   "source": [
    "It is now trained to detect additional labels! The model results here show all the labels training accuracy. Since only new labels existed in the dataset, only the new labels are given accuracy scores. Keep in mind this is a small dataset for brevity's sake and that real training would involve more samples and better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e110ee1c",
   "metadata": {},
   "source": [
    "## Saving and Loading a Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484d193",
   "metadata": {},
   "source": [
    "The Labeler can easily be saved or loaded with one simple line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8684fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure save directory exists\n",
    "if not os.path.exists('my_labeler'):\n",
    "    os.makedirs('my_labeler')\n",
    "\n",
    "# Saving the labeler\n",
    "labeler.save_to_disk(\"my_labeler\")\n",
    "\n",
    "# Loading the labeler\n",
    "labeler = dp.DataLabeler(labeler_type='structured', dirpath=\"my_labeler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36dec8",
   "metadata": {},
   "source": [
    "## Building a Labeler from the Ground Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59346d2b",
   "metadata": {},
   "source": [
    "As mentioned earlier, the labeler is comprised of three components, and each of the compenents can be created and interchanged in the the labeler pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dataprofiler.labelers.character_level_cnn_model import \\\n",
    "    CharacterLevelCnnModel\n",
    "from dataprofiler.labelers.data_processing import \\\n",
    "    StructCharPreprocessor, StructCharPostprocessor\n",
    "\n",
    "model = CharacterLevelCnnModel({\"PAD\":0, \"UNKNOWN\":1, \"Test_Label\":2})\n",
    "preprocessor = StructCharPreprocessor()\n",
    "postprocessor = StructCharPostprocessor()\n",
    "\n",
    "labeler = dp.DataLabeler(labeler_type='structured')\n",
    "labeler.set_preprocessor(preprocessor)\n",
    "labeler.set_model(model)\n",
    "labeler.set_postprocessor(postprocessor)\n",
    "\n",
    "# check for basic compatibility between the processors and the model\n",
    "labeler.check_pipeline()\n",
    "\n",
    "# Optionally set the parameters\n",
    "parameters={\n",
    "    'preprocessor':{\n",
    "        'max_length': 100,\n",
    "    },\n",
    "    'model':{\n",
    "        'max_length': 100,\n",
    "    },\n",
    "    'postprocessor':{\n",
    "        'random_state': random.Random(1)\n",
    "    }\n",
    "} \n",
    "labeler.set_params(parameters)\n",
    "\n",
    "labeler.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f020d7f",
   "metadata": {},
   "source": [
    "The components can each be created if you inherit the BaseModel and BaseProcessor for the model and processors, respectively. More info can be found about coding your own components in the Labeler section of the [documentation]( https://capitalone.github.io/dataprofiler). In summary, the Data Profiler open source library can be used to scan sensitive information in both structured and unstructured data with different file types. It supports multiple input formats and output formats at word and character levels. Users can also train the labeler on their own datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
