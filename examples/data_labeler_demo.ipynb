{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spoken-reunion",
   "metadata": {},
   "source": [
    "# Sensitive Data Detection with the Data Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-bidder",
   "metadata": {},
   "source": [
    "In this example, we utilize the Data Labeler component of the Data Profiler to detect the sensitive information for both structured and unstructured data. In addition, we show how to train the Data Labeler on some specific dataset with different list of entities.\n",
    "\n",
    "First, let's dive into what the Data Labeler is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965b83b",
   "metadata": {},
   "source": [
    "## What is the Data Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c643f",
   "metadata": {},
   "source": [
    "The Data Labeler is a pipeline designed to make building, training, and predictions with ML models quick and easy. There are 3 major components to the Data Labeler: the preprocessor, the model, and the postprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0aeb4",
   "metadata": {},
   "source": [
    "![alt text](DL-Flowchart.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550323c7",
   "metadata": {},
   "source": [
    "Each component can be switched out individually to suit your needs. As you might expect, the preprocessor takes in raw data and prepares it for the model, the model performs the prediction or training, and the postprocessor takes prediction results and turns them into human-readable results. \n",
    "\n",
    "Now let's run some examples. Start by importing all the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "scientific-stevens",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '..')\n",
    "import dataprofiler as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125b215",
   "metadata": {},
   "source": [
    "## Structured Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-devon",
   "metadata": {},
   "source": [
    "We'll use the aws honeypot dataset in the test folder for this example. First, look at the data using the Data Reader class of the Data Profiler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjusted-native",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>host</th>\n",
       "      <th>src</th>\n",
       "      <th>proto</th>\n",
       "      <th>type</th>\n",
       "      <th>srcport</th>\n",
       "      <th>destport</th>\n",
       "      <th>srcip</th>\n",
       "      <th>locale</th>\n",
       "      <th>localeabbr</th>\n",
       "      <th>postalcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>owner</th>\n",
       "      <th>comment</th>\n",
       "      <th>int_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/3/13 21:53</td>\n",
       "      <td>groucho-oregon</td>\n",
       "      <td>1032051418</td>\n",
       "      <td>TCP</td>\n",
       "      <td></td>\n",
       "      <td>6000</td>\n",
       "      <td>1433</td>\n",
       "      <td>61.131.218.218</td>\n",
       "      <td>Jiangxi Sheng</td>\n",
       "      <td>36</td>\n",
       "      <td></td>\n",
       "      <td>28.55</td>\n",
       "      <td>115.9333</td>\n",
       "      <td></td>\n",
       "      <td>He my polite be object oh change. Consider no ...</td>\n",
       "      <td>9464.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/3/13 21:57</td>\n",
       "      <td>groucho-oregon</td>\n",
       "      <td>1347834426</td>\n",
       "      <td>UDP</td>\n",
       "      <td></td>\n",
       "      <td>5270</td>\n",
       "      <td>5060</td>\n",
       "      <td>80.86.82.58</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3731.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/3/13 21:58</td>\n",
       "      <td>groucho-oregon</td>\n",
       "      <td>2947856490</td>\n",
       "      <td>TCP</td>\n",
       "      <td></td>\n",
       "      <td>2489</td>\n",
       "      <td>1080</td>\n",
       "      <td>175.180.184.106</td>\n",
       "      <td>Taipei</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>25.0392</td>\n",
       "      <td>121.525</td>\n",
       "      <td></td>\n",
       "      <td>Of on affixed civilly moments promise explain ...</td>\n",
       "      <td>3963.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/3/13 21:58</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UDP</td>\n",
       "      <td></td>\n",
       "      <td>43235</td>\n",
       "      <td>1900</td>\n",
       "      <td></td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "      <td>97124</td>\n",
       "      <td>45.5848</td>\n",
       "      <td>-122.9117</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1422.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/3/13 21:58</td>\n",
       "      <td>groucho-singapore</td>\n",
       "      <td>3587648279</td>\n",
       "      <td>TCP</td>\n",
       "      <td></td>\n",
       "      <td>56577</td>\n",
       "      <td>80</td>\n",
       "      <td>213.215.43.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>48.86</td>\n",
       "      <td>2.35</td>\n",
       "      <td></td>\n",
       "      <td>Affronting everything discretion men now own d...</td>\n",
       "      <td>9271.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime               host         src proto type srcport destport  \\\n",
       "0  3/3/13 21:53     groucho-oregon  1032051418   TCP         6000     1433   \n",
       "1  3/3/13 21:57     groucho-oregon  1347834426   UDP         5270     5060   \n",
       "2  3/3/13 21:58     groucho-oregon  2947856490   TCP         2489     1080   \n",
       "3  3/3/13 21:58                                  UDP        43235     1900   \n",
       "4  3/3/13 21:58  groucho-singapore  3587648279   TCP        56577       80   \n",
       "\n",
       "             srcip         locale localeabbr postalcode latitude  longitude  \\\n",
       "0   61.131.218.218  Jiangxi Sheng         36               28.55   115.9333   \n",
       "1      80.86.82.58                                            51          9   \n",
       "2  175.180.184.106         Taipei                        25.0392    121.525   \n",
       "3                          Oregon         OR      97124  45.5848  -122.9117   \n",
       "4    213.215.43.23                                         48.86       2.35   \n",
       "\n",
       "  owner                                            comment  int_col  \n",
       "0        He my polite be object oh change. Consider no ...  9464.00  \n",
       "1                                                           3731.00  \n",
       "2        Of on affixed civilly moments promise explain ...  3963.00  \n",
       "3                                                           1422.00  \n",
       "4        Affronting everything discretion men now own d...  9271.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dp.Data(\"../dataprofiler/tests/data/csv/aws_honeypot_marx_geo.csv\")\n",
    "df_data = data.data\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ccf8a",
   "metadata": {},
   "source": [
    "We can directly predict the labels of a structured dataset on the cell level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19529af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAD', 'UNKNOWN', 'ADDRESS', 'BAN', 'CREDIT_CARD', 'DATE', 'TIME', 'DATETIME', 'DRIVERS_LICENSE', 'EMAIL_ADDRESS', 'UUID', 'HASH_OR_KEY', 'IPV4', 'IPV6', 'MAC_ADDRESS', 'PERSON', 'PHONE_NUMBER', 'SSN', 'URL', 'US_STATE', 'INTEGER', 'FLOAT', 'QUANTITY', 'ORDINAL']\n",
      "\n",
      "\n",
      "{'PAD': 0, 'UNKNOWN': 1, 'ADDRESS': 2, 'BAN': 3, 'CREDIT_CARD': 4, 'DATE': 5, 'TIME': 6, 'DATETIME': 7, 'DRIVERS_LICENSE': 8, 'EMAIL_ADDRESS': 9, 'UUID': 10, 'HASH_OR_KEY': 11, 'IPV4': 12, 'IPV6': 13, 'MAC_ADDRESS': 14, 'PERSON': 15, 'PHONE_NUMBER': 16, 'SSN': 17, 'URL': 18, 'US_STATE': 19, 'INTEGER': 20, 'FLOAT': 21, 'QUANTITY': 22, 'ORDINAL': 23}\n",
      "\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x16771bd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x169524b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167859280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x16771bd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x169524b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167859280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "['DATETIME' 'UNKNOWN' 'PHONE_NUMBER' ... 'None' 'None' 'FLOAT']\n",
      "\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data_labeler = dp.DataLabeler(labeler_type='structured')\n",
    "\n",
    "# print out the labels and label mapping\n",
    "print(data_labeler.labels) \n",
    "print(\"\\n\")\n",
    "print(data_labeler.label_mapping)\n",
    "print(\"\\n\")\n",
    "\n",
    "# make predictions and get labels for each cell going row by row\n",
    "# predict options are model dependent and the default model can show prediction confidences\n",
    "predictions = data_labeler.predict(data, predict_options={\"show_confidences\": True})\n",
    "\n",
    "# display prediction results\n",
    "print(predictions['pred'])\n",
    "print(\"\\n\")\n",
    "\n",
    "# display confidence results\n",
    "print(predictions['conf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af72e2c",
   "metadata": {},
   "source": [
    "The profiler uses the data labeler to perform column by column predictions. The data contains 16 columns, each of which has different data label. Next, we will use the Data Labeler of the Data Profiler to predict the label for each column in this tabular dataset. To use only the labeling functionality, other options of the Data Profiler are disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secret-million",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.int.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.float.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.text.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the Null values in the columns... (with 15 processes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 10.01it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the statistics...  (with 4 processes)\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x169079430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x1677089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1690ee940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 1/16 [00:00<00:02,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x169079430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowOpLayer._defun_call at 0x1677089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function recreate_function.<locals>.restored_function_body at 0x1690ee940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 2/16 [00:00<00:02,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 16 calls to <function recreate_function.<locals>.restored_function_body at 0x169079430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 14 calls to <function TensorFlowOpLayer._defun_call at 0x1677089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 17 calls to <function recreate_function.<locals>.restored_function_body at 0x1690ee940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 4/16 [00:00<00:01,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x169079430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x1677089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1690ee940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [00:00<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x1677089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x1677089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function recreate_function.<locals>.restored_function_body at 0x1690ee940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 12/16 [00:01<00:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 18 calls to <function recreate_function.<locals>.restored_function_body at 0x169079430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowOpLayer._defun_call at 0x1677089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 19 calls to <function recreate_function.<locals>.restored_function_body at 0x1690ee940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column        Prediction\n",
      "0     datetime    DATETIME|FLOAT\n",
      "1         host           UNKNOWN\n",
      "2          src  BAN|PHONE_NUMBER\n",
      "3        proto           UNKNOWN\n",
      "4         type           INTEGER\n",
      "5      srcport           INTEGER\n",
      "6     destport           INTEGER\n",
      "7        srcip              IPV4\n",
      "8       locale           UNKNOWN\n",
      "9   localeabbr   INTEGER|UNKNOWN\n",
      "10  postalcode           INTEGER\n",
      "11    latitude             FLOAT\n",
      "12   longitude             FLOAT\n",
      "13       owner              None\n",
      "14     comment           UNKNOWN\n",
      "15     int_col             FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set options to only run the data labeler\n",
    "profile_options = dp.ProfilerOptions()\n",
    "profile_options.set({\"text.is_enabled\": False, \n",
    "                     \"int.is_enabled\": False, \n",
    "                     \"float.is_enabled\": False, \n",
    "                     \"order.is_enabled\": False, \n",
    "                     \"category.is_enabled\": False, \n",
    "                     \"datetime.is_enabled\": False,})\n",
    "\n",
    "profile = dp.Profiler(data, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "def get_structured_results(results):\n",
    "    columns = []\n",
    "    predictions = []\n",
    "    for col in results['data_stats']:\n",
    "        columns.append(col)\n",
    "        predictions.append(results['data_stats'][col]['data_label'])\n",
    "\n",
    "    df_results = pd.DataFrame({'Column': columns, 'Prediction': predictions})\n",
    "    return df_results\n",
    "\n",
    "results = profile.report()    \n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-louisville",
   "metadata": {},
   "source": [
    "The results show that the Data Profiler is able to detect sensitive information such as datetime, ipv4, or phone number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-diploma",
   "metadata": {},
   "source": [
    "## Unstructured Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-coaching",
   "metadata": {},
   "source": [
    "Besides structured data, the Data Profiler detects the sensitive information on the unstructured text. We use a sample of spam email in Enron email dataset for this demo. As above, we start investigating the content of the given email sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unauthorized-lounge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = \"Message-ID: <11111111.1111111111111.JavaMail.evans@thyme>\\n\" + \\\n",
    "        \"Date: Fri, 10 Aug 2005 11:31:37 -0700 (PDT)\\n\" + \\\n",
    "        \"From: w..smith@company.com\\n\" + \\\n",
    "        \"To: john.smith@company.com\\n\" + \\\n",
    "        \"Subject: RE: ABC\\n\" + \\\n",
    "        \"Mime-Version: 1.0\\n\" + \\\n",
    "        \"Content-Type: text/plain; charset=us-ascii\\n\" + \\\n",
    "        \"Content-Transfer-Encoding: 7bit\\n\" + \\\n",
    "        \"X-From: Smith, Mary W. </O=ENRON/OU=NA/CN=RECIPIENTS/CN=SSMITH>\\n\" + \\\n",
    "        \"X-To: Smith, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JSMITH>\\n\" + \\\n",
    "        \"X-cc: \\n\" + \\\n",
    "        \"X-bcc: \\n\" + \\\n",
    "        \"X-Folder: \\SSMITH (Non-Privileged)\\Sent Items\\n\" + \\\n",
    "        \"X-Origin: Smith-S\\n\" + \\\n",
    "        \"X-FileName: SSMITH (Non-Privileged).pst\\n\\n\" + \\\n",
    "        \"All I ever saw was the e-mail from the office.\\n\\n\" + \\\n",
    "        \"Mary\\n\\n\" + \\\n",
    "        \"-----Original Message-----\\n\" + \\\n",
    "        \"From:   Smith, John  \\n\" + \\\n",
    "        \"Sent:   Friday, August 10, 2005 13:07 PM\\n\" + \\\n",
    "        \"To:     Smith, Mary W.\\n\" + \\\n",
    "        \"Subject:        ABC\\n\\n\" + \\\n",
    "        \"Have you heard any more regarding the ABC sale? I guess that means that \" + \\\n",
    "        \"it's no big deal here, but you think they would have send something.\\n\\n\\n\" + \\\n",
    "        \"John Smith\\n\" + \\\n",
    "        \"123-456-7890\\n\"\n",
    "\n",
    "# convert string data to list to feed into the data labeler\n",
    "data = [data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-segment",
   "metadata": {},
   "source": [
    "By default, the Data Profiler predicts the results at the character level for unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "junior-acrobat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1620b9280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowOpLayer._defun_call at 0x16b18df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x166b96f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "       21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
      "       21., 22., 18., 18.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
      "        9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
      "        9.,  9.,  9.,  9.,  9.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        5.,  5.,  5.,  5., 20., 20.,  1.,  7.,  7.,  7.,  7.,  7.,  7.,\n",
      "        7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n",
      "        7.,  7.,  7.,  6.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
      "        9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  1.,  1.,\n",
      "        1.,  1.,  1.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
      "        9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1., 23., 23., 23.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 23., 23., 23.,\n",
      "       23., 23., 23., 23., 23.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1., 23., 23., 23., 23.,  1., 23.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
      "       15., 15.,  1., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
      "       11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
      "       11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
      "       11., 11., 11.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 15., 15.,\n",
      "       15., 15., 15., 15., 15., 15., 15., 15., 15.,  1., 11., 11., 11.,\n",
      "       11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
      "       11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
      "       11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 22.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1., 18.,  1., 22., 22., 22., 22.,\n",
      "       22.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  5.,  5.,  5.,  5.,\n",
      "        5.,  5.,  5.,  7.,  7.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
      "        5.,  5.,  5.,  5.,  5.,  5.,  1.,  6.,  6.,  6.,  6.,  6.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 15., 15.,\n",
      "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  8.,  1., 16., 16., 16., 16., 16., 16., 16.,\n",
      "       16., 16., 16., 16., 16.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "data_labeler = dp.DataLabeler(labeler_type='unstructured')\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = data_labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print(predictions['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-diabetes",
   "metadata": {},
   "source": [
    "In addition to the character-level result, the Data Profiler provides the results at the word level following the standard NER (Named Entity Recognition), e.g., utilized by spaCy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optical-universe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=======================Prediction======================\n",
      "\n",
      "<11111111: FLOAT\n",
      "--------------------------------------------------------\n",
      "JavaMail.evans@thyme>: EMAIL_ADDRESS\n",
      "--------------------------------------------------------\n",
      "Aug 2005 11:31:37 -0700: DATETIME\n",
      "--------------------------------------------------------\n",
      "smith@company.com: EMAIL_ADDRESS\n",
      "--------------------------------------------------------\n",
      "john.smith@company.com: EMAIL_ADDRESS\n",
      "--------------------------------------------------------\n",
      "text/plain: ORDINAL\n",
      "--------------------------------------------------------\n",
      "7bit: ORDINAL\n",
      "--------------------------------------------------------\n",
      "Smith, Mary W: PERSON\n",
      "--------------------------------------------------------\n",
      "</O=ENRON/OU=NA/CN=RECIPIENTS/CN=SSMITH>: HASH_OR_KEY\n",
      "--------------------------------------------------------\n",
      "Smith, John: PERSON\n",
      "--------------------------------------------------------\n",
      "</O=ENRON/OU=NA/CN=RECIPIENTS/CN=JSMITH>: HASH_OR_KEY\n",
      "--------------------------------------------------------\n",
      "Smith, John: PERSON\n",
      "--------------------------------------------------------\n",
      "Friday: DATE\n",
      "--------------------------------------------------------\n",
      "2005: DATE\n",
      "--------------------------------------------------------\n",
      "13:07: TIME\n",
      "--------------------------------------------------------\n",
      "Smith, Mary W: PERSON\n",
      "--------------------------------------------------------\n",
      "123-456-7890: PHONE_NUMBER\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# convert prediction to word format and ner format\n",
    "# Set the output to the NER format (start position, end position, label)\n",
    "data_labeler.set_params(\n",
    "    { 'postprocessor': { 'output_format':'ner', 'use_word_level_argmax':True } } \n",
    ")\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = data_labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print('\\n')\n",
    "print('=======================Prediction======================\\n')\n",
    "for pred in predictions['pred'][0]:\n",
    "    print('{}: {}'.format(data[0][pred[0]: pred[1]], pred[2]))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-tourism",
   "metadata": {},
   "source": [
    "Here, the Data Profiler is able to identify sensitive information such as datetime, email address, person names, and phone number in an email sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-disney",
   "metadata": {},
   "source": [
    "## Train the Data Labeler from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-twist",
   "metadata": {},
   "source": [
    "The Data Labeler can be trained from scratch with a new list of labels. Below, we show an example of training the Data Labeler on a dataset with labels given as the columns of that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "utility-evaluation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0, batch_id 1: loss: 3.078799 - acc: 0.357417 - f1_score 0.357417WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x16955c550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 373ms/step- f1_score 0.3782\n",
      "EPOCH 0, validation_batch_id 1(After removing non-entity tokens)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    datetime       0.16      0.21      0.19      5331\n",
      "        host       0.00      0.00      0.00      6422\n",
      "         src       0.00      0.00      0.00      4773\n",
      "       proto       0.00      0.00      0.00      1451\n",
      "        type       0.00      0.00      0.00        29\n",
      "     srcport       0.00      0.00      0.00      1807\n",
      "    destport       0.00      0.00      0.00      1641\n",
      "       srcip       0.00      0.00      0.00      6449\n",
      "      locale       0.00      0.00      0.00      3974\n",
      "  localeabbr       0.00      0.00      0.00       695\n",
      "  postalcode       0.00      0.00      0.00       436\n",
      "    latitude       0.00      0.00      0.00      2803\n",
      "   longitude       0.08      0.27      0.13      3246\n",
      "       owner       0.00      0.00      0.00         0\n",
      "     int_col       0.00      0.00      0.00      3599\n",
      "\n",
      "   micro avg       0.03      0.05      0.04     42656\n",
      "   macro avg       0.02      0.03      0.02     42656\n",
      "weighted avg       0.03      0.05      0.03     42656\n",
      "\n",
      "\n",
      "\n",
      "F1 Score:  0.022283612687855007\n",
      "EPOCH 0 (6s), loss: 3.122449 - acc: 0.378200 - f1_score 0.378200 -- val_f1: 0.032829 - val_precision: 0.026712 - val_recall 0.047567\n",
      "1/1 [==============================] - 0s 141ms/step- f1_score 0.5248\n",
      "EPOCH 1, validation_batch_id 1(After removing non-entity tokens)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    datetime       0.47      0.24      0.32      5331\n",
      "        host       0.32      0.99      0.48      6422\n",
      "         src       0.00      0.00      0.00      4773\n",
      "       proto       0.00      0.00      0.00      1451\n",
      "        type       0.00      0.00      0.00        29\n",
      "     srcport       0.00      0.00      0.00      1807\n",
      "    destport       0.00      0.00      0.00      1641\n",
      "       srcip       0.65      0.04      0.07      6449\n",
      "      locale       0.01      0.02      0.01      3974\n",
      "  localeabbr       0.00      0.00      0.00       695\n",
      "  postalcode       0.00      0.00      0.00       436\n",
      "    latitude       0.00      0.00      0.00      2803\n",
      "   longitude       0.17      0.61      0.27      3246\n",
      "       owner       0.00      0.00      0.00         0\n",
      "     int_col       0.00      0.00      0.00      3599\n",
      "\n",
      "   micro avg       0.21      0.23      0.22     42656\n",
      "   macro avg       0.12      0.14      0.08     42656\n",
      "weighted avg       0.22      0.23      0.15     42656\n",
      "\n",
      "\n",
      "\n",
      "F1 Score:  0.08253443565098162\n",
      "EPOCH 1 (3s), loss: 2.061414 - acc: 0.524835 - f1_score 0.524835 -- val_f1: 0.145023 - val_precision: 0.219144 - val_recall 0.232558\n",
      "1/1 [==============================] - 0s 147ms/step- f1_score 0.6627\n",
      "EPOCH 2, validation_batch_id 1(After removing non-entity tokens)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    datetime       0.62      0.22      0.32      5331\n",
      "        host       0.30      1.00      0.47      6422\n",
      "         src       0.00      0.00      0.00      4773\n",
      "       proto       0.00      0.00      0.00      1451\n",
      "        type       0.00      0.00      0.00        29\n",
      "     srcport       0.00      0.00      0.00      1807\n",
      "    destport       0.00      0.00      0.00      1641\n",
      "       srcip       0.99      0.38      0.55      6449\n",
      "      locale       0.03      0.07      0.04      3974\n",
      "  localeabbr       0.00      0.00      0.00       695\n",
      "  postalcode       0.00      0.00      0.00       436\n",
      "    latitude       0.00      0.00      0.00      2803\n",
      "   longitude       0.26      0.63      0.37      3246\n",
      "       owner       0.00      0.00      0.00         0\n",
      "     int_col       0.00      0.00      0.00      3599\n",
      "\n",
      "   micro avg       0.27      0.29      0.28     42656\n",
      "   macro avg       0.16      0.16      0.13     42656\n",
      "weighted avg       0.30      0.29      0.23     42656\n",
      "\n",
      "\n",
      "\n",
      "F1 Score:  0.12501434476433973\n",
      "EPOCH 2 (4s), loss: 1.446997 - acc: 0.662718 - f1_score 0.662718 -- val_f1: 0.225844 - val_precision: 0.295021 - val_recall 0.290205\n",
      "1/1 [==============================] - 0s 141ms/step- f1_score 0.7182\n",
      "EPOCH 3, validation_batch_id 1(After removing non-entity tokens)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    datetime       0.68      0.19      0.30      5331\n",
      "        host       0.29      1.00      0.46      6422\n",
      "         src       0.00      0.00      0.00      4773\n",
      "       proto       0.00      0.00      0.00      1451\n",
      "        type       0.00      0.00      0.00        29\n",
      "     srcport       0.00      0.00      0.00      1807\n",
      "    destport       0.00      0.00      0.00      1641\n",
      "       srcip       0.97      0.89      0.93      6449\n",
      "      locale       0.08      0.17      0.11      3974\n",
      "  localeabbr       0.00      0.00      0.00       695\n",
      "  postalcode       0.00      0.00      0.00       436\n",
      "    latitude       0.00      0.00      0.00      2803\n",
      "   longitude       0.25      0.36      0.30      3246\n",
      "       owner       0.00      0.00      0.00         0\n",
      "     int_col       0.00      0.00      0.00      3599\n",
      "\n",
      "   micro avg       0.33      0.35      0.34     42656\n",
      "   macro avg       0.16      0.19      0.15     42656\n",
      "weighted avg       0.30      0.35      0.28     42656\n",
      "\n",
      "\n",
      "\n",
      "F1 Score:  0.1493343181070668\n",
      "EPOCH 3 (4s), loss: 1.091179 - acc: 0.718259 - f1_score 0.718259 -- val_f1: 0.279398 - val_precision: 0.302998 - val_recall 0.353221\n",
      "INFO:tensorflow:Assets written to: data_labeler_saved/assets\n"
     ]
    }
   ],
   "source": [
    "data = dp.Data(\"../dataprofiler/tests/data/csv/aws_honeypot_marx_geo.csv\")\n",
    "\n",
    "# the column 'comment' is changed to UNKNOWN, as the data labeler requires at least one column with label UNKNOWN\n",
    "df = data.data.rename({'comment': 'UNKNOWN'}, axis=1)\n",
    "\n",
    "# split data to training and test set\n",
    "split_ratio = 0.2\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "data_train = df[:int((1 - split_ratio) * len(df))]\n",
    "data_test = df[int((1 - split_ratio) * len(df)):]\n",
    "\n",
    "# train a new data labeler with column names as labels\n",
    "if not os.path.exists('data_labeler_saved'):\n",
    "    os.makedirs('data_labeler_saved')\n",
    "\n",
    "data_labeler = dp.train_structured_labeler(\n",
    "    data=data_train,\n",
    "    save_dirpath=\"data_labeler_saved\",\n",
    "    epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-torture",
   "metadata": {},
   "source": [
    "The trained Data Labeler is then used by the Data Profiler to provide the prediction on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "answering-panel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.int.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.float.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.text.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the Null values in the columns... (with 15 processes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.26it/s]\n",
      " 12%|█▎        | 2/16 [00:00<00:01, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the statistics...  (with 4 processes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 4/16 [00:00<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function recreate_function.<locals>.restored_function_body at 0x16c6138b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 21.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column           Prediction\n",
      "0     datetime       host|longitude\n",
      "1         host                 host\n",
      "2          src                 host\n",
      "3        proto                 host\n",
      "4         type                  src\n",
      "5      srcport               locale\n",
      "6     destport               locale\n",
      "7        srcip                srcip\n",
      "8       locale                 host\n",
      "9   localeabbr         UNKNOWN|host\n",
      "10  postalcode               locale\n",
      "11    latitude     locale|longitude\n",
      "12   longitude  could not determine\n",
      "13       owner                 None\n",
      "14     UNKNOWN                 host\n",
      "15     int_col             destport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict with the data labeler object\n",
    "profile_options.set({'data_labeler.data_labeler_object': data_labeler})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-stand",
   "metadata": {},
   "source": [
    "Another way to use the trained Data Labeler is through the directory path of the saved labeler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "industrial-characterization",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.int.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.float.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:335: UserWarning: ProfilerOptions.structured_options.text.numeric_stats: The numeric stats are completely disabled.\n",
      "  warnings.warn(\"{}: The numeric stats are completely disabled.\"\n",
      "../dataprofiler/profilers/profiler_options.py:645: UserWarning: The data labeler passed in will be used, not through the directory of the default model\n",
      "  warnings.warn(\"The data labeler passed in will be used,\"\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the Null values in the columns... (with 15 processes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 11.15it/s]\n",
      " 12%|█▎        | 2/16 [00:00<00:00, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the statistics...  (with 4 processes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column           Prediction\n",
      "0     datetime       host|longitude\n",
      "1         host                 host\n",
      "2          src                 host\n",
      "3        proto                 host\n",
      "4         type                  src\n",
      "5      srcport               locale\n",
      "6     destport               locale\n",
      "7        srcip                srcip\n",
      "8       locale                 host\n",
      "9   localeabbr         UNKNOWN|host\n",
      "10  postalcode               locale\n",
      "11    latitude     locale|longitude\n",
      "12   longitude  could not determine\n",
      "13       owner                 None\n",
      "14     UNKNOWN                 host\n",
      "15     int_col             destport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict with the data labeler loaded from path\n",
    "profile_options.set({'data_labeler.data_labeler_dirpath': 'data_labeler_saved'})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acedba0",
   "metadata": {},
   "source": [
    "## Transfer Learning a Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15fb1f",
   "metadata": {},
   "source": [
    "Instead of training a model from scratch, we can also transfer learn to improve the model and/or extend the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0104c374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 285ms/step- f1_score 0.0245\n",
      "EPOCH 0, validation_batch_id 1(After removing non-entity tokens)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    datetime       0.00      0.00      0.00         0\n",
      "        host       0.00      0.00      0.00         0\n",
      "         src       0.00      0.00      0.00         0\n",
      "       proto       0.00      0.00      0.00         0\n",
      "        type       0.00      0.00      0.00         0\n",
      "     srcport       0.00      0.00      0.00         0\n",
      "    destport       0.00      0.00      0.00         0\n",
      "       srcip       0.00      0.00      0.00         0\n",
      "      locale       0.00      0.00      0.00         0\n",
      "  localeabbr       0.00      0.00      0.00         0\n",
      "  postalcode       0.00      0.00      0.00         0\n",
      "    latitude       0.00      0.00      0.00         0\n",
      "   longitude       0.00      0.00      0.00         0\n",
      "       owner       0.00      0.00      0.00         0\n",
      "     int_col       0.00      0.00      0.00         0\n",
      "       carat       0.00      0.00      0.00       753\n",
      "         cut       0.00      0.00      0.00      1246\n",
      "       color       0.00      0.00      0.00       196\n",
      "     clarity       0.07      0.39      0.13       637\n",
      "       depth       0.00      0.00      0.00       764\n",
      "       table       0.00      0.00      0.00       362\n",
      "       price       0.00      0.00      0.00       786\n",
      "           x       0.00      0.00      0.00       860\n",
      "           y       0.00      0.00      0.00       779\n",
      "           z       0.00      0.00      0.00       719\n",
      "\n",
      "   micro avg       0.02      0.03      0.02      7102\n",
      "   macro avg       0.01      0.04      0.01      7102\n",
      "weighted avg       0.01      0.03      0.01      7102\n",
      "\n",
      "\n",
      "\n",
      "F1 Score:  0.012525354969574038\n",
      "EPOCH 0 (2s), loss: 6.616220 - acc: 0.024552 - f1_score 0.024552 -- val_f1: 0.011234 - val_precision: 0.006699 - val_recall 0.034779\n",
      "1/1 [==============================] - 0s 48ms/step - f1_score 0.0292\n",
      "EPOCH 1, validation_batch_id 1(After removing non-entity tokens)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    datetime       0.00      0.00      0.00         0\n",
      "        host       0.00      0.00      0.00         0\n",
      "         src       0.00      0.00      0.00         0\n",
      "       proto       0.00      0.00      0.00         0\n",
      "        type       0.00      0.00      0.00         0\n",
      "     srcport       0.00      0.00      0.00         0\n",
      "    destport       0.00      0.00      0.00         0\n",
      "       srcip       0.00      0.00      0.00         0\n",
      "      locale       0.00      0.00      0.00         0\n",
      "  localeabbr       0.00      0.00      0.00         0\n",
      "  postalcode       0.00      0.00      0.00         0\n",
      "    latitude       0.00      0.00      0.00         0\n",
      "   longitude       0.00      0.00      0.00         0\n",
      "       owner       0.00      0.00      0.00         0\n",
      "     int_col       0.00      0.00      0.00         0\n",
      "       carat       0.00      0.00      0.00       753\n",
      "         cut       0.00      0.00      0.00      1246\n",
      "       color       0.00      0.00      0.00       196\n",
      "     clarity       0.08      0.54      0.15       637\n",
      "       depth       0.00      0.00      0.00       764\n",
      "       table       0.00      0.00      0.00       362\n",
      "       price       0.00      0.00      0.00       786\n",
      "           x       0.00      0.00      0.00       860\n",
      "           y       0.00      0.00      0.00       779\n",
      "           z       0.00      0.00      0.00       719\n",
      "\n",
      "   micro avg       0.03      0.05      0.03      7102\n",
      "   macro avg       0.01      0.05      0.01      7102\n",
      "weighted avg       0.01      0.05      0.01      7102\n",
      "\n",
      "\n",
      "\n",
      "F1 Score:  0.014522998296422488\n",
      "EPOCH 1 (0s), loss: 5.670412 - acc: 0.029286 - f1_score 0.029286 -- val_f1: 0.013026 - val_precision: 0.007535 - val_recall 0.048015\n"
     ]
    }
   ],
   "source": [
    "data = dp.Data(\"../dataprofiler/tests/data/csv/diamonds.csv\")\n",
    "df_data = data.data[:1000]\n",
    "df_data.head()\n",
    "\n",
    "# prep data\n",
    "df_data = df_data.reset_index(drop=True).melt()\n",
    "df_data.columns = [1, 0]  # labels=1, values=0 in that order\n",
    "df_data = df_data.astype(str)\n",
    "new_labels = df_data[1].unique().tolist()\n",
    "\n",
    "# load structured Data Labeler w/ trainable set to True\n",
    "data_labeler = dp.DataLabeler(labeler_type='structured', trainable=True, dirpath=\"data_labeler_saved\")\n",
    "\n",
    "# Reconstruct the model to add each new label\n",
    "for label in new_labels:\n",
    "    data_labeler.add_label(label)\n",
    "\n",
    "# this will use transfer learning to retrain the data labeler on your new\n",
    "# dataset and labels.\n",
    "# Setting labels with a list of labels or label mapping will overwrite the existing labels with new ones\n",
    "# Setting the reset_weights parameter to false allows transfer learning to occur\n",
    "model_results = data_labeler.fit(x=df_data[0], y=df_data[1], validation_split=0.2, \n",
    "                                 epochs=2, labels=None, reset_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78745f",
   "metadata": {},
   "source": [
    "Let's display the training results of the last epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b764aa8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Precision  Recall  F1-score  Support\n",
      "datetime        0.000      0.000   0.000           0\n",
      "host            0.000      0.000   0.000           0\n",
      "src             0.000      0.000   0.000           0\n",
      "proto           0.000      0.000   0.000           0\n",
      "type            0.000      0.000   0.000           0\n",
      "srcport         0.000      0.000   0.000           0\n",
      "destport        0.000      0.000   0.000           0\n",
      "srcip           0.000      0.000   0.000           0\n",
      "locale          0.000      0.000   0.000           0\n",
      "localeabbr      0.000      0.000   0.000           0\n",
      "postalcode      0.000      0.000   0.000           0\n",
      "latitude        0.000      0.000   0.000           0\n",
      "longitude       0.000      0.000   0.000           0\n",
      "owner           0.000      0.000   0.000           0\n",
      "int_col         0.000      0.000   0.000           0\n",
      "carat           0.000      0.000   0.000         753\n",
      "cut             0.000      0.000   0.000        1246\n",
      "color           0.000      0.000   0.000         196\n",
      "clarity         0.084      0.535   0.145         637\n",
      "depth           0.000      0.000   0.000         764\n",
      "table           0.000      0.000   0.000         362\n",
      "price           0.000      0.000   0.000         786\n",
      "x               0.000      0.000   0.000         860\n",
      "y               0.000      0.000   0.000         779\n",
      "z               0.000      0.000   0.000         719\n",
      "micro avg       0.025      0.048   0.033        7102\n",
      "macro avg       0.008      0.054   0.015        7102\n",
      "weighted avg    0.008      0.048   0.013        7102\n"
     ]
    }
   ],
   "source": [
    "print(\"{:14s}  Precision  Recall  F1-score  Support\".format(\"\"))\n",
    "for item in model_results[-1][2]:\n",
    "    print(\"{:14s}  {:4.3f}      {:4.3f}   {:4.3f}     {:7.0f}\".format(item,\n",
    "                                                                      model_results[-1][2][item][\"precision\"],\n",
    "                                                                      model_results[-1][2][item][\"recall\"],\n",
    "                                                                      model_results[-1][2][item][\"f1-score\"],\n",
    "                                                                      model_results[-1][2][item][\"support\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44009522",
   "metadata": {},
   "source": [
    "The model is now trained to detect additional labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd4171",
   "metadata": {},
   "source": [
    "## Saving and Loading a Data Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb37cca",
   "metadata": {},
   "source": [
    "The data labeler can easily be saved or loaded with one simple line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d70fbaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data_labeler_saved_again/assets\n"
     ]
    }
   ],
   "source": [
    "# Ensure save directory exists\n",
    "if not os.path.exists('my_data_labeler'):\n",
    "    os.makedirs('my_data_labeler')\n",
    "\n",
    "# Saving the data labeler\n",
    "data_labeler.save_to_disk(\"my_data_labeler\")\n",
    "\n",
    "# Loading the data labeler\n",
    "data_labeler = dp.DataLabeler(labeler_type='structured', dirpath=\"data_labeler_saved_again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36dec8",
   "metadata": {},
   "source": [
    "## Building a Data Labeler from the Ground Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59346d2b",
   "metadata": {},
   "source": [
    "As mentioned earlier, the data labeler is comprised of three components, and each of the compenents can be created and interchanged in the the data labeler pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprofiler as dp\n",
    "from dataprofiler.labelers.character_level_cnn_model import \\\n",
    "    CharacterLevelCnnModel\n",
    "from dataprofiler.labelers.data_processing import \\\n",
    "    StructCharPreprocessor, StructCharPostprocessor\n",
    "\n",
    "model = CharacterLevelCnnModel({\"PAD\":0, \"UNKNOWN\":1, \"Test_Label\":2})\n",
    "preprocessor = StructCharPreprocessor()\n",
    "postprocessor = StructCharPostprocessor()\n",
    "\n",
    "data_labeler = dp.DataLabeler(labeler_type='structured')\n",
    "data_labeler.set_preprocessor(preprocessor)\n",
    "data_labeler.set_model(model)\n",
    "data_labeler.set_postprocessor(postprocessor)\n",
    "\n",
    "# check for basic compatibility between the processors and the model\n",
    "data_labeler.check_pipeline()\n",
    "\n",
    "data_labeler.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f020d7f",
   "metadata": {},
   "source": [
    "The components can each be created if you inherit the BaseModel and BaseProcessor for the model and processors, respectively. More info can be found about coding your own components in the Labeler section of the [documentation]( https://capitalone.github.io/dataprofiler)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0bc30",
   "metadata": {},
   "source": [
    "### Setting Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65911538",
   "metadata": {},
   "source": [
    "When it comes to setting parameters of each component, it can easily be done by passing in a nested dictionary to the data labeler. Calling help() can reveal parameters to set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa557680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First call help() to learn what parameters are available\n",
    "data_labeler.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc4e37",
   "metadata": {},
   "source": [
    "These parameters can then be set by sending in a nested dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "parameters={\n",
    "    'preprocessor':{\n",
    "        'max_length': 100,\n",
    "    },\n",
    "    'model':{\n",
    "        'max_length': 100,\n",
    "    },\n",
    "    'postprocessor':{\n",
    "        'random_state': random.Random(1)\n",
    "    }\n",
    "} \n",
    "data_labeler.set_params(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-termination",
   "metadata": {},
   "source": [
    "In summary, the Data Profiler open source library can be used to scan sensitive information in both structured and unstructured data with different file types. It support multiple input formats and output formats at word and character levels. Users can also train the data labeler on their own datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
