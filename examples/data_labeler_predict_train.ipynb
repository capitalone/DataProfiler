{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dimensional-corner",
   "metadata": {},
   "source": [
    "# Sensitive data detection using the Data Labeler component of the Data Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-whole",
   "metadata": {},
   "source": [
    "In this example, we utilize the Data Labeler component of the Data Profiler to detect the sensitive information for both structured and unstructured data. In addition, we show how to train the Data Labeler on some specific dataset with different list of entities.\n",
    "\n",
    "First, let's import the libraries needed for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '..')\n",
    "import dataprofiler as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-shareware",
   "metadata": {},
   "source": [
    "## Structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-strength",
   "metadata": {},
   "source": [
    "We use the aws honeypot dataset in the test folder for this example. First, look at the data using Data Reader class of the Data Profiler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dp.Data(\"../dataprofiler/tests/data/csv/aws_honeypot_marx_geo.csv\")\n",
    "df_data = data.data\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-radio",
   "metadata": {},
   "source": [
    "The data contains 16 columns, each of which has different data label. Next, we will use Data Labeler of the Data Profiler to predict the label for each column in this tabular dataset. To use only the labeling functionality, other options of the Data Profiler are disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set option to only run the data labeler\n",
    "profile_options = dp.ProfilerOptions()\n",
    "profile_options.set({\"text.is_enabled\": False, \n",
    "                     \"int.is_enabled\": False, \n",
    "                     \"float.is_enabled\": False, \n",
    "                     \"order.is_enabled\": False, \n",
    "                     \"category.is_enabled\": False, \n",
    "                     \"datetime.is_enabled\": False,})\n",
    "\n",
    "profile = dp.Profiler(data, profiler_options=profile_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-progressive",
   "metadata": {},
   "source": [
    "The results are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction from data profiler\n",
    "def get_structured_results(results):\n",
    "    columns = []\n",
    "    predictions = []\n",
    "    for col in results['data_stats']:\n",
    "        columns.append(col)\n",
    "        predictions.append(results['data_stats'][col]['data_label'])\n",
    "\n",
    "    df_results = pd.DataFrame({'Column': columns, 'Prediction': predictions})\n",
    "    return df_results\n",
    "\n",
    "results = profile.report()    \n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-lighting",
   "metadata": {},
   "source": [
    "The results show that the Data Profiler is able to detect sensitive information such as datetime, ipv4, or address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-nigeria",
   "metadata": {},
   "source": [
    "### Train the Data Labeler from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-adolescent",
   "metadata": {},
   "source": [
    "The Data Labeler can be trained from scratch with the new list of labels. Below, we show an example of training the Data Labeler on a dataset with labels given as the columns of that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column 'comment' is changed to UNKNOWN, as data labeler requires at least one column with label UNKNOWN\n",
    "df = data.data.rename({'comment': 'UNKNOWN'}, axis=1)\n",
    "\n",
    "# split data to training and test set\n",
    "split_ratio = 0.2\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "data_train = df[:int((1 - split_ratio) * len(df))]\n",
    "data_test = df[int((1 - split_ratio) * len(df)):]\n",
    "\n",
    "# train a new data labeler with column names as labels\n",
    "if not os.path.exists('data_labeler_saved'):\n",
    "    os.makedirs('data_labeler_saved')\n",
    "\n",
    "data_labeler = dp.train_structured_labeler(\n",
    "    data=data_train,\n",
    "    save_dirpath=\"data_labeler_saved\",\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-month",
   "metadata": {},
   "source": [
    "The trained Data Labeler is then used by the Data Profiler to provide the prediction on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the data labeler object\n",
    "profile_options.set({'data_labeler.data_labeler_object': data_labeler})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-involvement",
   "metadata": {},
   "source": [
    "Another way to use the trained Data Labeler is through the directory path of the saved labeler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the data labeler loaded from path\n",
    "profile_options.set({'data_labeler.data_labeler_dirpath': 'data_labeler_saved'})\n",
    "profile = dp.Profiler(data_test, profiler_options=profile_options)\n",
    "\n",
    "# get the prediction from the data profiler\n",
    "results = profile.report()\n",
    "print(get_structured_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-error",
   "metadata": {},
   "source": [
    "## Unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-matthew",
   "metadata": {},
   "source": [
    "Beside structured data, Data Profiler detects the sensitive information on the unstructured text. We use a sample of spam email in Enron email dataset for this demo. As above, we start investigating the content of the given email sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = \"Message-ID: <11111111.1111111111111.JavaMail.evans@thyme>\\n\" + \\\n",
    "        \"Date: Fri, 10 Aug 2005 11:31:37 -0700 (PDT)\\n\" + \\\n",
    "        \"From: w..smith@company.com\\n\" + \\\n",
    "        \"To: john.smith@company.com\\n\" + \\\n",
    "        \"Subject: RE: ABC\\n\" + \\\n",
    "        \"Mime-Version: 1.0\\n\" + \\\n",
    "        \"Content-Type: text/plain; charset=us-ascii\\n\" + \\\n",
    "        \"Content-Transfer-Encoding: 7bit\\n\" + \\\n",
    "        \"X-From: Smith, Mary W. </O=ENRON/OU=NA/CN=RECIPIENTS/CN=SSMITH>\\n\" + \\\n",
    "        \"X-To: Smith, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JSMITH>\\n\" + \\\n",
    "        \"X-cc: \\n\" + \\\n",
    "        \"X-bcc: \\n\" + \\\n",
    "        \"X-Folder: \\SSMITH (Non-Privileged)\\Sent Items\\n\" + \\\n",
    "        \"X-Origin: Smith-S\\n\" + \\\n",
    "        \"X-FileName: SSMITH (Non-Privileged).pst\\n\\n\" + \\\n",
    "        \"All I ever saw was the e-mail from the office.\\n\\n\" + \\\n",
    "        \"Mary\\n\\n\" + \\\n",
    "        \"-----Original Message-----\\n\" + \\\n",
    "        \"From:   Smith, John  \\n\" + \\\n",
    "        \"Sent:   Friday, August 10, 2005 13:07 PM\\n\" + \\\n",
    "        \"To:     Smith, Mary W.\\n\" + \\\n",
    "        \"Subject:        ABC\\n\\n\" + \\\n",
    "        \"Have you heard any more regarding the ABC sale? I guess that means that \" + \\\n",
    "        \"it's no big deal here, but you think they would have send something.\\n\\n\\n\" + \\\n",
    "        \"John Smith\\n\" + \\\n",
    "        \"123-456-7890\\n\"\n",
    "\n",
    "# convert string data to list to feed into the data labeler\n",
    "data = [data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-exhaust",
   "metadata": {},
   "source": [
    "By default, Data Profiler predicts the results at the character level for unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeler = dp.DataLabeler(labeler_type='unstructured')\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = data_labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print(predictions['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-soviet",
   "metadata": {},
   "source": [
    "In addition to the character-level result, Data Profiler provides the results at the word level following the standard NER (Named Entity Recognition), e.g., utilized by spaCy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prediction to word format and ner format\n",
    "# Set the output to the NER format (start position, end position, label)\n",
    "data_labeler.set_params(\n",
    "    { 'postprocessor': { 'output_format':'ner', 'use_word_level_argmax':True } } \n",
    ")\n",
    "\n",
    "# make predictions and get labels per character\n",
    "predictions = data_labeler.predict(data)\n",
    "\n",
    "# display results\n",
    "print('\\n')\n",
    "print('=======================Prediction======================\\n')\n",
    "for pred in predictions['pred'][0]:\n",
    "    print('{}: {}'.format(data[0][pred[0]: pred[1]], pred[2]))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-efficiency",
   "metadata": {},
   "source": [
    "Here, Data Profiler is able to identify sensitive information such as datetime, email address, person names, and phone number in an email sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-jimmy",
   "metadata": {},
   "source": [
    "In summary, the Data Profiler open source library can be used to scan sensitive information in both structured and unstructured data with different file types. It support multiple input formats and output formats at word and character levels. Users can also train the data labeler on their own datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
