{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "- **Expectation Used:** [expect_column_values_to_be_equal_to_or_less_than_profile_max](https://github.com/great-expectations/great_expectations/blob/develop/contrib/capitalone_dataprofiler_expectations/capitalone_dataprofiler_expectations/expectations/expect_column_values_to_be_equal_to_or_less_than_profile_max.py)\n",
    "- **Expectation Description:** This expectation will take the report of an initial dataset and compare it to the report which is generated by an additional dataset of the same schema. The expectation is that the user specified column should contain values less than or equal to the max value metric generated in the report of the initial dataset.\n",
    "- **Use Case:** If a user has data that tracks the daily spending on an account, they might want some data quality checks to track when daily spending reaches an all-time high. With this expectation, as new data is generated based on daily spending, it will raise an expectation violation if the new data indicates higher spending than the max daily spending recorded previously by this account. This is one very practical use for fraud monitoring and detection.\n",
    "- **Example Details:** In this example, we are using this expectation to check the max age found in the original datasets report against all the age values in the new dataset. The expectation is that all the ages in the new dataset should be less than the max age of the original dataset, otherwise a violation will be raised indicating exactly what values caused a violation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Great expectations imports\n",
    "import great_expectations as ge\n",
    "from capitalone_dataprofiler_expectations.expectations. \\\n",
    "    expect_column_values_to_be_equal_to_or_less_than_profile_max \\\n",
    "    import ExpectColumnValuesToBeEqualToOrLessThanProfileMax\n",
    "from great_expectations.self_check.util import build_pandas_validator_with_data\n",
    "\n",
    "# Data Profiler import\n",
    "import dataprofiler as dp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup\n",
    "Below we going to import a dataset from the Data Profiler testing suite. This csv holds information on gun crimes statistics across 3 different years."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "context = ge.get_context()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "guns_data_path = \"../../dataprofiler/tests/data/csv/guns.csv\"\n",
    "df = pd.read_csv(guns_data_path)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example we are going to split up the dataset into three separate years so we can simulate a dataset which will have a yearly aggregation of data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sort_values(by=\"year\", axis=0, inplace=True)\n",
    "years = df[\"year\"].unique().tolist()\n",
    "years.reverse()\n",
    "years"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the years, we will capture all records from each year in their own dataframes, so we can process them separately."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "individual_dataframes = []\n",
    "for year in years:\n",
    "    current_year_df = df.loc[df[\"year\"]==year]\n",
    "    current_year_df = current_year_df.drop(\"year\", axis=1).drop(\"month\", axis=1)\n",
    "    individual_dataframes.append(current_year_df)\n",
    "individual_dataframes[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will create a report on the first `individual_dataframe` which corresponds to the year 2014, then we will output the `max` metric from the `age` column as found in the report."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "profiler_options = dp.ProfilerOptions()\n",
    "profiler_options.set({\"data_labeler.is_enabled\": False})\n",
    "profile = dp.Profiler(individual_dataframes[0], len(individual_dataframes[0]), options=profiler_options)\n",
    "report  = profile.report(report_options={\"output_format\": \"compact\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "report['data_stats'][3]['statistics']['max']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running the Expectation\n",
    "We build the validator by passing in the `individual_dataframe` corresponding to 2013. Then we will use the exception below to find values in the `age` column that exceed the `max` metric for the `age` column generated in `report`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validator = build_pandas_validator_with_data(individual_dataframes[1])\n",
    "results = validator.expect_column_values_to_be_equal_to_or_less_than_profile_max(\n",
    "    column='age',\n",
    "    profile=report\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results\n",
    "After we generate the expectation we find that there is one row with a value that exceeds the max age from the previous report with 107 as well as 11 rows with missing values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}