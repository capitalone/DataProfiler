{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ded4fa",
   "metadata": {},
   "source": [
    "# DataProfiler - Profilers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3af8a7",
   "metadata": {},
   "source": [
    "Data profiling is the process of examining a dataset and collecting statistical or informational summaries about said dataset.\n",
    "\n",
    "The Profilers inside the DataProfiler is designed to calculate multiple statistics, make predictions on the entities inside a given column / key-value store (via the Labeler) and generally determine informational summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, '..')\n",
    "import dataprofiler as dp\n",
    "\n",
    "data_path = \"../dataprofiler/tests/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5704f2d",
   "metadata": {},
   "source": [
    "## Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d1850",
   "metadata": {},
   "source": [
    "One of the primary purposes of the Profiler are to quickly identify what's in the dataset. This can be useful for analyzing a dataset prior to use or determining which columns could be useful for a given purpose.\n",
    "\n",
    "In terms of reporting, there are four reporting options:\n",
    "\n",
    "* **Pretty**: floats are rounded to four decimal places, and lists are shortened.\n",
    "* **Compact**: Similar to pretty, but removes detailed statistics such as runtimes, label probabilities, index locations of null types, etc.\n",
    "* **Serializable**: Output is json serializable and not prettified\n",
    "* **Flat**: Nested output is returned as a flattened dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2382cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dp.Data(os.path.join(data_path, \"csv/aws_honeypot_marx_geo.csv\"))\n",
    "profile = dp.Profiler(data)\n",
    "\n",
    "# Compact - A high level view, good for quick reviews\n",
    "report  = profile.report(report_options={\"output_format\":\"compact\"})\n",
    "print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25da71f",
   "metadata": {},
   "source": [
    "The report includes `global_stats` and `data_stats` for the given dataset. The former contains overall properties of the data such as number of rows/columns, null ratio, duplicate ratio, while the later contains specific properties and statistics for each column such as min, max, mean, variance, etc. In this example, the `compact` format of the report is used to shorten the full list of the results. To get more results related to detailed predictions at the entity level from the DataLabeler component or histogram results, the format `pretty` should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3f83b",
   "metadata": {},
   "source": [
    "In addition to reading the input data from multiple file types, DataProfiler allows the input data as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run data profiler and get the report\n",
    "my_dataframe = pd.DataFrame([[1, 2.0],[1, 2.2],[-1, 3]], columns=[\"col_int\", \"col_float\"])\n",
    "profile = dp.Profiler(my_dataframe)\n",
    "\n",
    "report  = profile.report(report_options={\"output_format\":\"compact\"})\n",
    "print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ca3d6",
   "metadata": {},
   "source": [
    "## Profiler options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43553238",
   "metadata": {},
   "source": [
    "DataProfiler can run several selected components if needed. For example, if the users only want the statistics information, they may turn off the DataLabeler functionality. Below, let's remove the histogram and data labeler component while running DataProfiler. \n",
    "\n",
    "Full list of options: https://capitalone.github.io/DataProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_options = dp.ProfilerOptions()\n",
    "profile_options.set({\n",
    "    \"histogram.is_enabled\": False,\n",
    "    \"data_labeler.is_enabled\": False\n",
    "})\n",
    "\n",
    "profile = dp.Profiler(data, profiler_options=profile_options)\n",
    "report  = profile.report(report_options={\"output_format\":\"compact\"})\n",
    "\n",
    "# Print the report\n",
    "print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430bfd6",
   "metadata": {},
   "source": [
    "### Updating Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c88460b",
   "metadata": {},
   "source": [
    "Beyond just profiling, one of the unique aspects of the DataProfiler (as compared to pandas-profiling) is the ability to update the profiles. To update appropriately, the schema (columns / keys) must match appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73126e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and profile a CSV file\n",
    "data = dp.Data(os.path.join(data_path, \"csv/sparse-first-and-last-column-header-and-author.txt\"))\n",
    "profile = dp.Profiler(data)\n",
    "\n",
    "# Update the profile with new data:\n",
    "new_data = dp.Data(os.path.join(data_path, \"csv/sparse-first-and-last-column-skip-header.txt\"))\n",
    "profile.update_profile(new_data)\n",
    "\n",
    "# Report the compact version of the profile\n",
    "report  = profile.report(report_options={\"output_format\":\"compact\"})\n",
    "print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5122d6",
   "metadata": {},
   "source": [
    "### Merging Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9475a1",
   "metadata": {},
   "source": [
    "Merging profiles are an alternative method for updating profiles. Particularly, multiple profiles can be generated seperately, then added together with a simple `+` command: `profile3 = profile1 + profile2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d750fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file with a schema\n",
    "data1 = dp.Data(os.path.join(data_path, \"csv/sparse-first-and-last-column-header-and-author.txt\"))\n",
    "profile1 = dp.Profiler(data1)\n",
    "\n",
    "# Load another CSV file with the same schema\n",
    "data2 = dp.Data(os.path.join(data_path, \"csv/sparse-first-and-last-column-skip-header.txt\"))\n",
    "profile2 = dp.Profiler(data2)\n",
    "\n",
    "# Merge the profiles\n",
    "profile3 = profile1 + profile2\n",
    "\n",
    "# Report the compact version of the profile\n",
    "report  = profile3.report(report_options={\"output_format\":\"compact\"})\n",
    "print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac98b6",
   "metadata": {},
   "source": [
    "As you can see, the `update_profile` function and the `+` operator function similarly. The reason the `+` operator is important is that it's possible to *save and load profiles*, which we cover next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25b209",
   "metadata": {},
   "source": [
    "### Saving and Loading a Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c3f5d",
   "metadata": {},
   "source": [
    "Not only can the Profiler create and update profiles, it's also possible to save profiles. This is critical as it is possible to generate multiple profiles and save them, then later load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd909646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file, with \",\" as the delimiter\n",
    "filenames = [\n",
    "    \"csv/sparse-first-and-last-column-header-and-author.txt\",\n",
    "    \"csv/sparse-first-and-last-column-skip-header.txt\"\n",
    "]\n",
    "\n",
    "data_objects = []\n",
    "for filename in filenames:\n",
    "    data_objects.append(dp.Data(os.path.join(data_path, filename)))\n",
    "\n",
    "\n",
    "# Generate and save profiles\n",
    "for i in range(len(data_objects)):\n",
    "    profile = dp.Profiler(data_objects[i])\n",
    "    profile.save(filepath=\"data-\"+str(i)+\".pkl\")\n",
    "\n",
    "\n",
    "# Load profiles and add them together\n",
    "profile = None\n",
    "for i in range(len(data_objects)):\n",
    "    saved_profile_name = \"data-\"+str(i)+\".pkl\"\n",
    "    profile_tmp = dp.Profiler.load(saved_profile_name)\n",
    "    if profile is None:\n",
    "        profile = profile_tmp\n",
    "    else:\n",
    "        profile += profile_tmp\n",
    "\n",
    "\n",
    "# Report the compact version of the profile\n",
    "report = profile.report(report_options={\"output_format\":\"compact\"})\n",
    "print(json.dumps(report, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
